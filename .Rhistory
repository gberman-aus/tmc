library(quanteda)
library(readtext)
# make sure we are in the right directory
setwd('//home/gberman/github/tmc')
# Load the .yml files
configs <- read_yaml('configuration/corpus_config.yml')
# Load the .csv file
df <- read.csv('data/intermediate/code_extracted.csv')
names(df)
# Convert it to a corpus
corp_df <- corpus(df, text_field = "TextNoCode")
docnames(corp_df) <- df$Id
# Add metadata
meta_data <- configs$corpus_format$data_columns
for (metas in meta_data){
docvars(corp_df, metas) <- names(df$metas)
}
# save the corpus
saveRDS(corp_df, 'data/intermediate/corpus.RDS')
# create tokens
tokens_df <- tokens(corp_df,
remove_punct = TRUE,
remove_numbers = FALSE,
remove_symbols = TRUE,
remove_url = TRUE,
remove_separators = TRUE)
# remove stopwords
tokens_df <- tokens_select(tokens_df,
pattern = stopwords("en"),
selection = "remove")
# if stemming, do that
if (configs$`document-term_matrix_options`$stemming == 1){
tokens_df <- tokens_wordstem(tokens_df)
print("Stemming.")
} else {print("No stemming.")}
# if using n-grams, create the n-grams and update the tokens
if (configs$`document-term_matrix_options`$`n-grams` > 1){
tokens_df <- tokens_ngrams(tokens_df, n = 1:(configs$`document-term_matrix_options`$`n-grams`+1))
print("Creating n-grams.")
} else {print("No n-grams created.")}
# save the tokens
saveRDS(tokens_df, 'data/intermediate/tokens.RDS')
# create document frequency matrix
dfm_df <- dfm(tokens_df)
dfm_df <- dfm_trim(dfm_df,
min_termfreq = configs$`document-term_matrix_options`$min_term_frequency)
dfm_df <- dfm_trim(dfm_df,
max_docfreq = configs$`document-term_matrix_options`$max_doc_frquency, docfreq_type = "prop")
if (configs$`document-term_matrix_options`$dtm_method == 2) {
dfm_df <- dfm_tfidf(dfm_df)
print("Using term frequency-inverse document frequency.")
} else {
print("Using term occurence.")
}
# save the document frequency matrix
saveRDS(dfm_df, 'data/processed/dfm.RDS')
# clean up
rm(configs, df, dfm_df, tokens_df , corp_df, meta_data, metas)
# Requirements
library(yaml)
library(stm)
# make sure we are in the right directory
setwd('//home/gberman/github/tmc')
# Load the .yml files
configs <- read_yaml('configuration/corpus_config.yml')
# Load the .RDS dfm file
dtm <- readRDS('data/processed/dfm.RDS')
# convert the dfm format for the stm package
dtm <- convert(dtm, to = "stm")
trainings <- read_yaml('configuration/training_config.yml')
training_plan <- read_yaml('configuration/training_config.yml')
rm(trainings)
# search for the best number of topics
topic_range <- seq(from = training_plan$K_value_range$min_K, to = training_plan$K_value_range$max_K, by = training_plan$K_value_range$K_interval)
# Requirements
library(yaml)
library(stm)
# make sure we are in the right directory
setwd('//home/gberman/github/tmc')
# Load the .yml files
configs <- read_yaml('configuration/corpus_config.yml')
training_plan <- read_yaml('configuration/training_config.yml')
# Load the .RDS dfm file
dtm <- readRDS('data/processed/dfm.RDS')
# convert the dfm format for the stm package
dtm <- convert(dtm, to = "stm")
# search for the best number of topics
topic_range <- seq(from = training_plan$K_value_range$min_K, to = training_plan$K_value_range$max_K, by = training_plan$K_value_range$K_interval)
ManyTop<- manyTopics(documents = dtm$documents,
vocab = dtm$vocab,
K = topic_range,
max.em.its = 100,
data = dtm$meta,
init.type = "Spectral",
seed=180587,
runs=50)
saveRDS(ManyTop, 'results/models/manytopics.RDS')
# identify data relevant topics
dtopics <- list()
for(i in 1:length(topic_range)){
dtopics[[i]] <- findTopic(ManyTop$out[[i]], n = 15, c("data"))
}
# Plot Topic Summaries
for(i in 1:length(topic_range)) {
pdf(file = paste0("plots/SummaryMT", nameX[i], ".pdf"), width = 12, height = 8)
plot(ManyTop$out[[i]], xlim = c(0,0.1), text.cex = 0.5, n = 15,
main = paste0(nameX[i], " ", "Topics"))
dev.off()
}
# Plot Topic Summaries
for(i in 1:length(topic_range)) {
pdf(file = paste0("plots/SummaryMT", topic_range[i], ".pdf"), width = 12, height = 8)
plot(ManyTop$out[[i]], xlim = c(0,0.1), text.cex = 0.5, n = 15,
main = paste0(nameX[i], " ", "Topics"))
dev.off()
}
# Plot Topic Summaries
for(i in 1:length(topic_range)) {
pdf(file = paste0("results/outputs", topic_range[i], ".pdf"), width = 12, height = 8)
plot(ManyTop$out[[i]], xlim = c(0,0.1), text.cex = 0.5, n = 15,
main = paste0(topic_range[i], " ", "Topics"))
dev.off()
}
# Plot Topic Summaries
for(i in 1:length(topic_range)) {
pdf(file = paste0("results/outputs/", topic_range[i], ".pdf"), width = 12, height = 8)
plot(ManyTop$out[[i]], xlim = c(0,0.1), text.cex = 0.5, n = 15,
main = paste0(topic_range[i], " ", "Topics"))
dev.off()
}
# identify data relevant topics
dtopics <- list()
for(i in 1:length(topic_range)){
dtopics[[i]] <- findTopic(ManyTop$out[[i]], n = 15, c("machine"))
}
# identify data relevant topics
dtopics <- list()
for(i in 1:length(topic_range)){
dtopics[[i]] <- findTopic(ManyTop$out[[i]], n = 15, c("jupyt"))
}
# Plot Topic Summaries
for(i in 1:length(topic_range)) {
pdf(file = paste0("results/outputs/", topic_range[i], ".pdf"), width = 12, height = 8)
plot(ManyTop$out[[i]], xlim = c(0,0.1), text.cex = 0.5, n = 15,
main = paste0(topic_range[i], " ", "Topics"))
dev.off()
}
# Plot Topic Summaries
for(i in 1:length(topic_range)) {
pdf(file = paste0("results/outputs/", topic_range[i], ".pdf"), width = 12, height = 8)
plot(ManyTop$out[[i]],text.cex = 0.5, n = 15,
main = paste0(topic_range[i], " ", "Topics"))
dev.off()
}
# make TC01 TC05, Topic Correlation Networks list
TC01 <- list()
TC05 <- list()
for(i in 1:length(topic_range)) {
TC01[[i]] <- topicCorr(ManyTop$out[[i]], method = "simple", cutoff = 0.01)
TC05[[i]] <- topicCorr(ManyTop$out[[i]], method = "simple", cutoff = 0.05)
}
# make igraph igTCO1 igTC05 list for plotting
igTC01 <-list()
igTC05 <-list()
for(i in 1:length(topic_range)) {
igTC01[[i]] <- graph_from_adjacency_matrix(TC01[[i]]$poscor, mode = "undirected",
weighted = TRUE, diag = FALSE)
igTC05[[i]] <- graph_from_adjacency_matrix(TC05[[i]]$poscor, mode = "undirected",
weighted = TRUE, diag = FALSE)
# set edge width
E(igTC01[[i]])$width <- E(igTC01[[i]])$weight*50
E(igTC05[[i]])$width <- E(igTC05[[i]])$weight*50
# side by side plot of networks and export as pdf
pdf(file = paste0("results/outputs/TC0105", topic_range[i], "fr.pdf"), width = 12, height = 8)
par(mfrow = c(1,2))
plot(igTC01[[i]], layout = layout_with_fr,
vertex.size = degree(igTC01[[i]], mode = "all")*0.5,
main = paste0(topic_range[i], " ", "Topics Correlation Network (cutoff = 0.01)")
)
plot(igTC05[[i]], layout = layout_with_fr,
vertex.size = degree(igTC05[[i]], mode = "all")*1.5,
main = paste0(topic_range[i], " ", "Topics Correlation Network (cutoff = 0.05)")
)
dev.off()
# reset edge width for 4 up plot
E(igTC01[[i]])$width <- E(igTC01[[i]])$weight*10
E(igTC05[[i]])$width <- E(igTC05[[i]])$weight*10
# 4 up community detection (using NG and GO) plot and export as pdf
pdf(file = paste0("results/outputs/TCCD0105", topic_range[i], "fr.pdf"), width = 12, height = 8)
par(mfrow = c(2,2))
# plot community detection using NG cutoff = 0.01
plot(cluster_edge_betweenness(igTC01[[i]]), igTC01[[i]],
vertex.size = degree(igTC01[[i]], mode = "all")*0.5,
main = paste0(topic_range[i], " ", "Topics Community Detection (Newman-Girvan, cutoff = 0.01)"))
# plot community detection using NG cutoff = 0.05
plot(cluster_edge_betweenness(igTC05[[i]]), igTC05[[i]],
vertex.size = degree(igTC05[[i]], mode = "all")*1.5,
main = paste0(topic_range[i], " ", "Topics Community Detection (Newman-Girvan, cutoff = 0.05)"))
# plot community detection using GO cutoff = 0.01
plot(cluster_fast_greedy(as.undirected(igTC01[[i]])), as.undirected(igTC01[[i]]),
vertex.size = degree(igTC01[[i]], mode = "all")*0.5,
main = paste0(topic_range[i], " ", "Topics Community Detection (Greedy-Optimisation, cutoff = 0.01)"))
# plot community detection using GO cutoff = 0.05
plot(cluster_fast_greedy(as.undirected(igTC05[[i]])), as.undirected(igTC05[[i]]),
vertex.size = degree(igTC05[[i]], mode = "all")*1.5,
main = paste0(topic_range[i], " ", "Topics Community Detection (Greedy-Optimisation, cutoff = 0.05)"))
dev.off()
}
install.packages("igraph")
library(igraph)
renv::snapshot()
rm(dtopics)
for(i in 1:length(topic_range)) {
igTC01[[i]] <- graph_from_adjacency_matrix(TC01[[i]]$poscor, mode = "undirected",
weighted = TRUE, diag = FALSE)
igTC05[[i]] <- graph_from_adjacency_matrix(TC05[[i]]$poscor, mode = "undirected",
weighted = TRUE, diag = FALSE)
# set edge width
E(igTC01[[i]])$width <- E(igTC01[[i]])$weight*50
E(igTC05[[i]])$width <- E(igTC05[[i]])$weight*50
# side by side plot of networks and export as pdf
pdf(file = paste0("results/outputs/TC0105", topic_range[i], "fr.pdf"), width = 12, height = 8)
par(mfrow = c(1,2))
plot(igTC01[[i]], layout = layout_with_fr,
vertex.size = degree(igTC01[[i]], mode = "all")*0.5,
main = paste0(topic_range[i], " ", "Topics Correlation Network (cutoff = 0.01)")
)
plot(igTC05[[i]], layout = layout_with_fr,
vertex.size = degree(igTC05[[i]], mode = "all")*1.5,
main = paste0(topic_range[i], " ", "Topics Correlation Network (cutoff = 0.05)")
)
dev.off()
# reset edge width for 4 up plot
E(igTC01[[i]])$width <- E(igTC01[[i]])$weight*10
E(igTC05[[i]])$width <- E(igTC05[[i]])$weight*10
# 4 up community detection (using NG and GO) plot and export as pdf
pdf(file = paste0("results/outputs/TCCD0105", topic_range[i], "fr.pdf"), width = 12, height = 8)
par(mfrow = c(2,2))
# plot community detection using NG cutoff = 0.01
plot(cluster_edge_betweenness(igTC01[[i]]), igTC01[[i]],
vertex.size = degree(igTC01[[i]], mode = "all")*0.5,
main = paste0(topic_range[i], " ", "Topics Community Detection (Newman-Girvan, cutoff = 0.01)"))
# plot community detection using NG cutoff = 0.05
plot(cluster_edge_betweenness(igTC05[[i]]), igTC05[[i]],
vertex.size = degree(igTC05[[i]], mode = "all")*1.5,
main = paste0(topic_range[i], " ", "Topics Community Detection (Newman-Girvan, cutoff = 0.05)"))
# plot community detection using GO cutoff = 0.01
plot(cluster_fast_greedy(as.undirected(igTC01[[i]])), as.undirected(igTC01[[i]]),
vertex.size = degree(igTC01[[i]], mode = "all")*0.5,
main = paste0(topic_range[i], " ", "Topics Community Detection (Greedy-Optimisation, cutoff = 0.01)"))
# plot community detection using GO cutoff = 0.05
plot(cluster_fast_greedy(as.undirected(igTC05[[i]])), as.undirected(igTC05[[i]]),
vertex.size = degree(igTC05[[i]], mode = "all")*1.5,
main = paste0(topic_range[i], " ", "Topics Community Detection (Greedy-Optimisation, cutoff = 0.05)"))
dev.off()
}
warnings()
rm(testing)
#save an R image
save.image("results/outputs/manytopics.RData")
#clean up
rm(configs, dtm, training_plan, topic_range, ManyTop, igTC01, igTC05, TC01, TC05)
rm(i)
packageVersion('renv')
print("testing R")
?renv
renv::clean()
renv::snapshot()
library(yaml)
installed.packages('yaml')
install.packages('yaml')
renv::snapshot()
renv::init()
renv::init()
renv::update()
renv::snapshot()
renv::repair()
renv::status()
# Requirements
library(yaml)
library(stm)
library(igraph)
source("manyTopics_iterative_saving.R")
source("manyTopics_iterative_saving.R")
working_directory <- Sys.getenv("working_path")
# make sure we are in the right directory
setwd(working_directory)
if(!exists("manyTopicsIterative")){
source(paste(working_directory, "src/R/manyTopics_iterative_saving.R"))
}
working_directory <- "Home/github/tmc"
# make sure we are in the right directory
setwd(working_directory)
if(!exists("manyTopicsIterative")){
source(paste(working_directory, "src/R/manyTopics_iterative_saving.R",sep="/"))
}
library(stm)
getwd()
loadRDS("projects/StackExchangeTest2/outputs/models/model_K25.RDS")
df <- readRDS("projects/StackExchangeTest2/outputs/models/model_K25.RDS")
summary(df)
plot(df)
rm(df)
rm(working_directory)
K5 <- readRDS('projects/StackExchange/outputs/models/model_K5.RDS')
K10 <- readRDS('projects/StackExchange/outputs/models/model_K10.RDS')
K15 <- readRDS('projects/StackExchange/outputs/models/model_K15.RDS')
K20 <- readRDS('projects/StackExchange/outputs/models/model_K20.RDS')
K25 <- readRDS('projects/StackExchange/outputs/models/model_K25.RDS')
summary(K25)
library(stm)
summary(K25)
# An R script for stitching the outputs of ManyTopicsIterative together into exclusivity vs semantic coherence charts
# requirements
library(st
# An R script for stitching the outputs of ManyTopicsIterative together into exclusivity vs semantic coherence charts
# requirements
library(st
# requirements
library(stm)
library(yaml)
working_directory <- Sys.getenv("working_path")
getwd()
# Load the .yml files
configs <- read_yaml('configuration/corpus_config.yml')
training_plan <- read_yaml('configuration/training_config.yml')
project_path <- paste('projects', configs$project_details$name, sep="/")
project_path <- "projects/StackExchange"
# Load all the .RDS files in /project_name/outputs/models
list_RDS <- list.files(path = paste(project_path, "outputs/models/", sep="/"), pattern = "*.RDS")
# Load all the .RDS files in /project_name/outputs/models
list_models <- list.files(path = paste(project_path, "outputs/models/", sep="/"), pattern = "*.RDS")
list_exclusivity <- list.files(path = paste(project_path, "outputs/exclusivity/", sep="/"), pattern = "*.RDS")
list_semcoh <- list.files(path = paste(project_path, "outputs/semcoh/", sep="/"), pattern = "*.RDS")
rm(list_RDS)
models <- lapply(list_models, readRDS)
# Update the list of files to include the path
for (i in list_models){
print(list_models[i])
}
# Update the list of files to include the path
for (i in list_models){
print(list_models[[i]])
}
# Update the list of files to include the path
for (i in list_models){
print(i)
}
# Update the list of files to include the path
for (i in list_models){
}
# Update the list of files to include the path
for (i in list_models){
print(paste(project_path, "outputs/models", i, sep="/"))
}
# Update the list of files to include the path
for (i in list_models){
i <- paste(project_path, "outputs/models", i, sep="/")
}
# Update the list of files to include the path
for (i in 1:length(list_models)){
list_models[i] <- paste(project_path, "outputs/models", i, sep="/")
}
models <- lapply(list_models, readRDS)
# Update the list of files to include the path
for (i in 1:length(list_models)){
list_models[i] <- paste(project_path, "outputs/models", list_models[i], sep="/")
}
models <- lapply(list_models, readRDS)
print(list_models)
# Load all the .RDS files in /project_name/outputs/models
list_models <- list.files(path = paste(project_path, "outputs/models/", sep="/"), pattern = "*.RDS")
# Update the list of files to include the path
for (i in 1:length(list_models)){
list_models[i] <- paste(project_path, "outputs/models", list_models[i], sep="/")
}
models <- lapply(list_models, readRDS)
View(models)
models <- do.call("rbind", models)
View(models)
View(models)
rm(models)
# Load all the .RDS files in /project_name/outputs/models
list_models <- list.files(path = paste(project_path, "outputs/models/", sep="/"), pattern = "*.RDS")
list_exclusivity <- list.files(path = paste(project_path, "outputs/exclusivity/", sep="/"), pattern = "*.RDS")
list_semcoh <- list.files(path = paste(project_path, "outputs/semcoh/", sep="/"), pattern = "*.RDS")
for (i in 1:length(list_models)){
list_models[i] <- paste(project_path, "outputs/models", list_models[i], sep="/")
runout[[i]] <- readRDS(list_models[i])
}
# initiate variables
runout <- list()
semcoh <- list()
exclusivity <- list()
# Load all the .RDS files in /project_name/outputs/models
list_models <- list.files(path = paste(project_path, "outputs/models/", sep="/"), pattern = "*.RDS")
list_exclusivity <- list.files(path = paste(project_path, "outputs/exclusivity/", sep="/"), pattern = "*.RDS")
list_semcoh <- list.files(path = paste(project_path, "outputs/semcoh/", sep="/"), pattern = "*.RDS")
for (i in 1:length(list_models)){
list_models[i] <- paste(project_path, "outputs/models", list_models[i], sep="/")
runout[[i]] <- readRDS(list_models[i])
}
for (i in 1:length(list_exclusivity)){
list_exclusivity[i] <- paste(project_path, "outputs/exclusivity", list_exclusivity[i], sep="/")
exclusivity[[i]] <- readRDS(list_exclusivity[i])
}
for (i in 1:length(list_semcoh)){
list_semcoh[i] <- paste(project_path, "outputs/semcoh", list_semcoh[i], sep="/")
semcoh[[i]] <- readRDS(list_semcoh[i])
}
out <- list(runout, semcoh, exclusivity)
plotModels(out)
class(out) <- "selectModel"
out <- list(runout, semcoh, exclusivity)
plotModels(out)
# initiate variables
runout <- list()
semcoh <- list()
exclusivity <- list()
sparsity <- list()
# Load all the .RDS files in /project_name/outputs/models
list_models <- list.files(path = paste(project_path, "outputs/models/", sep="/"), pattern = "*.RDS")
list_exclusivity <- list.files(path = paste(project_path, "outputs/exclusivity/", sep="/"), pattern = "*.RDS")
list_semcoh <- list.files(path = paste(project_path, "outputs/semcoh/", sep="/"), pattern = "*.RDS")
list_sparsity <- list.files(path = paste(project_path, "outputs/sparsity/", sep="/", pattern = "*.RDS"))
print(list_sparsity)
length(list_sparsity)
for (i in 1:length(list_models)){
list_models[i] <- paste(project_path, "outputs/models", list_models[i], sep="/")
runout[[i]] <- readRDS(list_models[i])
}
if (length(list_exclusivty) > 0){
for (i in 1:length(list_exclusivity)){
list_exclusivity[i] <- paste(project_path, "outputs/exclusivity", list_exclusivity[i], sep="/")
exclusivity[[i]] <- readRDS(list_exclusivity[i])
}
} else {
for (i in 1:length(list_models)){
exlcusivity[i] <- "Exclusivity not calculated for models with content covariates"
}
}
if (length(list_exclusivity) > 0){
for (i in 1:length(list_exclusivity)){
list_exclusivity[i] <- paste(project_path, "outputs/exclusivity", list_exclusivity[i], sep="/")
exclusivity[[i]] <- readRDS(list_exclusivity[i])
}
} else {
for (i in 1:length(list_models)){
exlcusivity[i] <- "Exclusivity not calculated for models with content covariates"
}
}
for (i in 1:length(list_semcoh)){
list_semcoh[i] <- paste(project_path, "outputs/semcoh", list_semcoh[i], sep="/")
semcoh[[i]] <- readRDS(list_semcoh[i])
}
if (length(list_sparsity) > 0){
for (i in 1:length(list_sparsity)){
list_sparsity[i] <- paste(project_path, "outputs/sparsity", list_sparsity[i], sep="/")
sparsity[[i]] <- readRDS(list_sparsity[i])
}
} else {
for (i in 1:length(list_models)){
sparsity[i] <- "Sparsity not calculated for models without content covariates"
}
}
class(out) <- "selectModel"
out <- list(runout=runout, semcoh=semcoh, exclusivity=exlcusivity, sparsity=sparsity)
# initiate variables
runout <- list()
semcoh <- list()
exclusivity <- list()
sparsity <- list()
# Load all the .RDS files in /project_name/outputs/models
list_models <- list.files(path = paste(project_path, "outputs/models/", sep="/"), pattern = "*.RDS")
list_exclusivity <- list.files(path = paste(project_path, "outputs/exclusivity/", sep="/"), pattern = "*.RDS")
list_semcoh <- list.files(path = paste(project_path, "outputs/semcoh/", sep="/"), pattern = "*.RDS")
list_sparsity <- list.files(path = paste(project_path, "outputs/sparsity/", sep="/", pattern = "*.RDS"))
for (i in 1:length(list_models)){
list_models[i] <- paste(project_path, "outputs/models", list_models[i], sep="/")
runout[[i]] <- readRDS(list_models[i])
}
if (length(list_exclusivity) > 0){
for (i in 1:length(list_exclusivity)){
list_exclusivity[i] <- paste(project_path, "outputs/exclusivity", list_exclusivity[i], sep="/")
exclusivity[[i]] <- readRDS(list_exclusivity[i])
}
} else {
for (i in 1:length(list_models)){
exclusivity[i] <- "Exclusivity not calculated for models with content covariates"
}
}
for (i in 1:length(list_semcoh)){
list_semcoh[i] <- paste(project_path, "outputs/semcoh", list_semcoh[i], sep="/")
semcoh[[i]] <- readRDS(list_semcoh[i])
}
if (length(list_sparsity) > 0){
for (i in 1:length(list_sparsity)){
list_sparsity[i] <- paste(project_path, "outputs/sparsity", list_sparsity[i], sep="/")
sparsity[[i]] <- readRDS(list_sparsity[i])
}
} else {
for (i in 1:length(list_models)){
sparsity[i] <- "Sparsity not calculated for models without content covariates"
}
}
class(out) <- "selectModel"
out <- list(runout=runout, semcoh=semcoh, exclusivity=exclusivity, sparsity=sparsity)
plotModels(out)
plot(out)
saveRDS(out, paste(project_path, "outputs/models/combined_models.RDS", sep="/"))
rm(list = ls())
gc()
